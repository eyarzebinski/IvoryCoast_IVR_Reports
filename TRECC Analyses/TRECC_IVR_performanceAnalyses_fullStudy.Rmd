---
title: "TRECC IVR Performance Analyses - 2019 Full Study"
author: "Evelyn Yarzebinski, Benjamin Zinszer, Mackenzie Campbell"
output:
   html_document:
     toc: true
     toc_float: true
     theme: united
---

##Note: This report filters for child users only.

##0. Metadata
```{r prep data, echo = F, include = F}
#clean up environment
rm(list=ls())
gc(verbose=TRUE)

source("TRECC_IVR_dataPrep_fullStudy_HD.R")

#now filter for children only for this report
UASdata = UASdata %>%
  filter(userRole == "child")

interactionsData = interactionsData %>%
  filter(userRole == "child")

cdrData_autoGenerate = cdrData_autoGenerate %>%
  filter(userRole == "child")

cdrData_userCalls = cdrData_userCalls %>%
  filter(userRole == "child")


knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
)
```

###Report Generation
```{r report time, echo = F}
message(paste("report generated: ",Sys.time(),sep=""))

```

###Range of dates in the datasets
```{r date range, echo = F}
UAS_maxDate = max(UASdata$date)
UAS_minDate = min(UASdata$date)
CDR_maxDate = max(cdrData_userCalls$date)
CDR_minDate = min(cdrData_userCalls$date)
interactions_maxDate = max(interactionsData$date)
interactions_minDate = min(interactionsData$date)
UAS_nDays = UAS_maxDate - UAS_minDate + 1
CDR_nDays = CDR_maxDate - CDR_minDate + 1
interactions_nDays = interactions_maxDate - interactions_minDate + 1
messageOutput = ifelse((UAS_nDays == CDR_nDays & CDR_nDays == interactions_nDays), 
                 paste("The data ranges from ", UAS_minDate," to ", UAS_maxDate,". The span is ",UAS_nDays," days.", sep = ""),
                 paste("Note: date ranges do not match. Check the user_answer_stats table and confirm whether students answered questions today."))

message(messageOutput)
#message(paste("user_answer_stats ranges from ", UAS_minDate," to ", UAS_maxDate,". The span is ",UAS_nDays," days.", sep = ""))
#message(paste("cdr_ivr01 ranges from ", CDR_minDate, " to ", CDR_maxDate,". The span is ",CDR_nDays," days.", sep = ""))
#message(paste("interactions ranges from ", interactions_minDate, " to ", interactions_maxDate,". The span is ",interactions_nDays," days.", sep = ""))

```

```{r saving, include=F}

#UASdata = UASdata %>%
#  select(-c(users.mobile_number, sessions.mobile_number, localPhoneNumber))

#write.csv(UASdata,paste("~/Documents/IvoryCoast/data/UASdata_currentDataThrough_",UAS_maxDate,".csv",sep=""),row.names = FALSE)
#write.xlsx(UASdata,paste("~/Documents/IvoryCoast/data/UASdata_currentDataThrough_",UAS_mostRecentDate,".xlsx",sep=""),row.names = FALSE)
#write.csv(cdrData_filter,paste0("~/Documents/IvoryCoast/data/cdrData_currentDataThrough_",CDR_mostRecentDate,".csv"),row.names = FALSE)
#write.xlsx(cdrData_filter,paste("~/Documents/IvoryCoast/data/cdrData_currentDataThrough_",CDR_mostRecentDate,".xlsx",sep=""),row.names = FALSE)
```

###Explore the data
####Below is a general table that displays basic information for each token, by trialDifficulty and tokenDifficulty. On the far right of the table is the average accuracy on the first attempt vs last attempt. On 3-option questions, users were given 2 attempts. However, for 2-option question, users were given only one attempt, so the firstAcc / lastAcc columns in the 2-option table will be the same.
###{.tabset}
####Tokens in 2 option questions
```{r Ben data exploration 2 options, echo = F}

UASdata.tokenid_2 = UASdata.tokenid %>%
  filter(options == 2)

datatable(
  UASdata.tokenid_2, 
  extensions = 'FixedColumns',
  rownames = FALSE,
  options = list(
    scrollX = TRUE,
    scrollCollapse = TRUE
))
```

####Tokens in 3 option questions
```{r Ben data exploration 3 options, echo = F}

UASdata.tokenid_3 = UASdata.tokenid %>%
  filter(options == 3)

datatable(
  UASdata.tokenid_3, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

##1. Trial Summary
###Exploratory tables
####Originally, these were called "question templates" and then became "VOS" (voice output structure) or even "question frames" - basically, the raw question structure that different tokens are plugged into. This table is populated with the trials that children have experienced so far.

###{.tabset}
####Number of Questions Per Lesson
```{r questions per lesson, echo = F}
questionsPerLesson = UASdata %>%
  group_by(UAS.unit_id, cmsQuestions.question_number, UAS.question_id, UAS.lesson_id) %>%
  summarize(nQuestionsPerLesson = n_distinct(UAS.question_id))

questionsPerLesson_V02 = questionsPerLesson %>%
  group_by(UAS.unit_id, cmsQuestions.question_number) %>%
  summarize(nLessons = n_distinct(UAS.lesson_id),
            avgQuestionsPerLesson = round(mean(nQuestionsPerLesson),2),
            lessonsWithLessThan5Q = length(nQuestionsPerLesson[nQuestionsPerLesson<=4]),
            min = min(nQuestionsPerLesson),
            max = max(nQuestionsPerLesson))

datatable(
  questionsPerLesson_V02, 
  extensions = 'FixedColumns',
  rownames = FALSE,
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))

```

####Unique Question Types and Performance
```{r VOS performance, echo = F}
questionPerformance = UASdata %>%
  group_by(UAS.unit_id,cmsQuestions.question_number) %>%
  summarize(nUsers = n_distinct(treccId_phoneId),
            totalAttempts = sum(UAS.number_of_attempts),
          avgCorrectnessOfQuestionAttempts = round(mean(UAS.correct),2))

datatable(
  questionPerformance, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Question List
####The full list of all unique combinations of question_type and token A/B/C combinations that students have attempted
####{.tabset}
#####All Questions
```{r question list, echo= F}
questionList = UASdata %>%
  group_by(UAS.unit_id, cmsQuestions.question_number,cmsQuestions.difficulty_level_trial,cmsQuestions.question_text) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            nAttempts = sum(UAS.completed),
            avgCorrectness = round(mean(UAS.correct),2))

datatable(
  questionList, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

#####Questions Repeated Multiple Days
```{r, echo = F}
questionList_Repeated = UASdata %>%
  group_by(UAS.unit_id, treccId_phoneId,cmsQuestions.question_number,cmsQuestions.difficulty_level_trial,cmsQuestions.question_text) %>%
  summarize(nDays = n_distinct(date),
            nAttempts = sum(UAS.completed),
            avgCorrectness = round(mean(UAS.correct),2)) %>%
  filter(nDays > 1)

datatable(
  questionList_Repeated, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Summary of Question Distribution
####This provides a quick debug reference.
```{r question summary, echo = F}
message(
  paste0("Currently across all units: ",n_distinct(questionList$cmsQuestions.question_text)," unique questions."),"\n",
  paste0("There are ",nrow(questionList)," rows in the Question List above.")
  )

```

<!-- ###Does a single question have multiple difficulty values? -->
<!-- ```{r} -->
<!-- #output the questions with multiple difficulty levels. should this be? -->


<!-- ``` -->

###What is the accuracy range for a trial?
####Two-option questions cannot be re-attempted, so FirstAcc = LastAcc.
####Three-option questions can be re-attempted once, so FirstAcc != LastAcc.

```{r, echo = F}
datatable(
  UASdata.trialid, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Comparing student performance across quartile splits on given unit/question types
####The plot shows the quartile split of all questions a student receives (x axis) by the average % correct on that quartile of questions (y axis). Each combination of a unit and question in its own plot (each plot's title corresponds to "Unit#_Question#"). From Quartile 1 ("Q-1") to Quartile 4 ("Q-4""), we would hope to see the students performing better. If not, it may indicate question difficulty, technical difficulty, student unreadiness, etc.

####{.tabset} 
#####Table
```{r performance first lesson vs current lesson, echo = F}

performanceFirstLessonToCurrent = UASdata %>%
  filter(UAS.unit_id != 5) %>%
  group_by(treccId_phoneId, UAS.unit_id, cmsQuestions.question_number) %>%
  mutate(questionAndUnit_concat = paste0(UAS.unit_id, "_",cmsQuestions.question_number),
         questionMax = max(questionNumberPerUnit),
         questionQuartile = questionNumberPerUnit / questionMax,
    #questionQuantile = rank(questionNumberPerUnit)/length(unique(questionNumberPerUnit)),
         questionQuartileGroup = ifelse(questionQuartile < .25, "Q-1", 
                                        ifelse(questionQuartile >= .75, "Q-2", 
                                               ifelse(questionQuartile >= .5, "Q-3", "Q-4")))) %>%
  group_by(treccId_phoneId, questionAndUnit_concat,currentUnit,questionQuartileGroup) %>%
  summarize(avgCorrectPercent = round(mean(UAS.correct),2),
            sdCorrectPercent = round(sd(UAS.correct),2),
            nQuestions = n_distinct(questionNumberOverall))
  # group_by(questionAndUnit_concat, questionQuantileGroup) %>%
  # summarize(avgCorrectPercent = round(mean(avgCorrectPercent),2),
  #           sdCorrectPercent = round(sd(sdCorrectPercent),2),
  #           avgNQuestions = round(mean(nQuestions),2),
  #           sdNQuestions = round(sd(nQuestions),2),
  #           nStudents = n_distinct(treccId_phoneId))

datatable(
  performanceFirstLessonToCurrent, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

#####Plot
```{r, echo=F}
 performanceFirstLessonToCurrent %>%
  ggplot(aes(x = questionQuartileGroup, y = avgCorrectPercent)) +
   geom_jitter(alpha = .2, width = .2) +
   #stat_smooth() +
   facet_wrap(~ questionAndUnit_concat, ncol = 5)
```



##2. Token Summary

###Token Distribution
####difficulty_level_token increases by 1 if certain phonemes don't exist in AttiÃ© and also if the token contains a certain syllable structure in a given question.
####difficulty_level_trial increases by 1 for each shared phoneme (in the same position) between tokens in a given question.
```{r token distribution, echo = F}
tokensInQuestions = UASdata %>%
  group_by(UAS.unit_id, cmsQuestions.question_number, cmsQuestions.difficulty_level_trial, cmsQuestions.difficulty_level_token) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            totalUniqueQuestions = n_distinct(cmsQuestions.id),
            totalAttempts = sum(UAS.completed),
            uniqueTokenA = n_distinct(cmsQuestions.token_a_id),
            uniqueTokenB = n_distinct(cmsQuestions.token_b_id),
            uniqueTokenC = n_distinct(cmsQuestions.token_c_id))

datatable(
  tokensInQuestions, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```


###Token Breakdown 
####The full list of all tokens that have appeared in positions A, B, and C, as well as the number of appearances, students experiencing the token, and attempts, as well as average correctness of those attempts.
####Sorting by avgAttemptCorrectness reveals a number of token_ids that have an average correctness below chance. This may indicate a number of different possibilities: the token is very difficult, the token is not being played so students are guessing because they hear silence, their environment was noisy and so they didn't hear the options, etc.

###{.tabset}

#### Token A List (correct answers)
```{r token list A, echo = F}
tokenDistribution_A = UASdata %>%
  group_by(cmsQuestions.token_a_id, phonetics_auditory_token_a, spelling_visual_token_a) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            uniqueQuestionTypesWithTokenA = n_distinct(cmsQuestions.id),
            countAttempts = sum(UAS.completed),
            avgAttemptCorrectness = round(mean(UAS.correct),2))


datatable(
  tokenDistribution_A, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

####Token B List (distractor)
```{r token list B, echo = F}
tokenDistribution_B = UASdata %>%
  group_by(cmsQuestions.token_b_id, phonetics_auditory_token_b, spelling_visual_token_b) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            uniqueQuestionsTypesWithTokenB = n_distinct(cmsQuestions.id),
            countAttempts = sum(UAS.completed),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(
  tokenDistribution_B, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
  
```

####Token C List (distractor)
```{r token list C, echo = F}
tokenDistribution_C = UASdata %>%
  group_by(cmsQuestions.token_c_id, phonetics_auditory_token_c, spelling_visual_token_c) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            uniqueQuestionTypesWithTokenC = n_distinct(cmsQuestions.id),
            countAttempts = sum(UAS.completed),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(
  tokenDistribution_C, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Distractor Token Co-Occurrence?
####distractor_token value of "null" occurs on true/false questions only.
```{r distractor token co-occurrence, echo = F}

tokenDistribution_distractorBC = UASdata %>%
  ungroup() %>%
  group_by(cmsQuestions.distractor_tokens_V02, cmsQuestions.distractor_tokens_IPA, cmsQuestions.distractor_tokens_spelling) %>%
  summarize(nStudents = n_distinct(treccId_phoneId),
            uniqueQuestionTypesWithTokenPair = n_distinct(cmsQuestions.id),
            countAttempts = sum(UAS.completed),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(
  tokenDistribution_distractorBC, 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Summary of Token Distribution
####For quick debug.
```{r token summary, echo = F}
message(
  paste0("Currently across all tokens: ",nrow(tokenDistribution_A)," unique token As, ",nrow(tokenDistribution_B), " unique token Bs, and ",nrow(tokenDistribution_C)," unique token Cs have been used in at least one question with at least one student.\nThere are ",nrow(tokenDistribution_distractorBC)," unique combinations of Tokens B and C."))
```

###General token presentation
####The histogram indicates the number of times tokens were presented. Bin width = 1, so the first bar represents the tokens presented only one time, etc. Tokens are not represented in this table if they have not been presented to any students.

```{r, echo = F}

UASdata.tokenid %>%
  ggplot(aes(x = presentations)) +
  geom_histogram(binwidth = 1)

#original hist code from Ben
#hist(UASdata.tokenid$presentations)
tweight.mean <- round(mean(UASdata.tokenid$presentations),2)
tweight.sd <- round(sd(UASdata.tokenid$presentations),2)

# Low frequency tokens (code included for completeness, but commented out for now)
# Spoiler, there aren't any (since the zero-frequency tokens don't get included)
#UASdata.tokenid[UASdata.tokenid$presentations < tweight.mean-2*tweight.sd,]
```


###High-Frequency Token Presentation
####Tokens appear here based on standard deviation of selection rates.

```{r, echo = F}
# High frequency tokens

datatable(
  UASdata.tokenid[UASdata.tokenid$presentations > tweight.mean+2*tweight.sd,], 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))

```

###Which tokens have low accuracy in first and last attempts?
####Low accuracy on first attempts - When there are at least 5 presentations to average across, and accuracy is equal to or below chance.

####{.tabset}
#####Plot
```{r, echo = F}
# UASdata.tokenid %>%
#   ggplot(aes(x = FirstAcc, col = options)) +
#   geom_histogram(binwidth = .1 )

ggplot() + 
  geom_histogram(data = UASdata.tokenid_2, aes(x = as.numeric(FirstAcc), fill = "b"),binwidth = .1, alpha = 0.3) +
  geom_histogram(data = UASdata.tokenid_3, aes(x = as.numeric(FirstAcc), fill = "y"),binwidth = .1, alpha = 0.3) +
  scale_fill_manual(labels = c("2 options", "3 options"), values=c("#FF0033", "#0066FF")) +
  labs(x = "FirstAcc") +
  guides(fill=guide_legend(title="First Accuracy"))

```

#####Table
```{r, echo = F}
#hist(UASdata.tokenid$FirstAcc)
# Low accuracy first-attempts: 
# When there are at least 5 presentations to average across, and accuracy is equal to or below chance

datatable(
  UASdata.tokenid[UASdata.tokenid$zFirstAcc<=0 & UASdata.tokenid$presentations>=5,], 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

####Low accuracy on last attempts - When there are at least 5 presentations to average across, and accuracy is equal to or below chance.

####{.tabset}
#####Plot
```{r, echo = F}
# UASdata.tokenid %>%
#   ggplot(aes(x = LastAcc)) +
#   geom_histogram(binwidth = .1 )

ggplot() + 
  geom_histogram(data = UASdata.tokenid_2, aes(x = as.numeric(LastAcc), fill = "b"),binwidth = .1, alpha = 0.3) +
  geom_histogram(data = UASdata.tokenid_3, aes(x = as.numeric(LastAcc), fill = "y"),binwidth = .1, alpha = 0.3) +
  scale_fill_manual(labels = c("2 options", "3 options"), values=c("#FF0033", "#0066FF")) +
  labs(x = "LastAcc") +
  guides(fill=guide_legend(title="Last Accuracy"))
```

#####Table
```{r, echo = F}
#hist(UASdata.tokenid$LastAcc)
# Low accuracy last-attempts tokens:
# When there are at least 5 presentations to average across, and accuracy is near or below chance
# Even some greater-than-chance results included, because they should be learnable by 3rd attempt

datatable(
  UASdata.tokenid[UASdata.tokenid$zLastAcc<=1 & UASdata.tokenid$presentations>=5,], 
  extensions = 'FixedColumns',
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))

```





###Does token difficulty rating accurately predict first- or last-attempt performance? 
####First attempt includes 2- and 3-option questions. Last attempt includes only 3-option questions.
###{.tabset}

####First Attempt (difficulty)

```{r, echo = F}
corFirst = cor.test(UASdata.tokenid$tokenDifficulty, UASdata.tokenid$zFirstAcc,weights=UASdata.tokenid$presentations)

corFirst

message(
  paste0("Correlation estimate is ", round(corFirst$estimate,3), ifelse(abs(corFirst$estimate)<.2, " (flat)",
                                   ifelse(abs(corFirst$estimate)<.4, " (weak)",
                                          ifelse(abs(corFirst$estimate)<.6, " (moderate)", " (strong)"))))
)

```   
 
####Last Attempt (learnability)
```{r, echo = F}
corLast = cor.test(UASdata.tokenid_3$tokenDifficulty, UASdata.tokenid_3$zLastAcc,weights=UASdata.tokenid$presentations)

corLast

message(
  paste0("Correlation estimate is ", round(corLast$estimate,3), ifelse(abs(corLast$estimate)<.2, " (flat)",
                                   ifelse(abs(corLast$estimate)<.4, " (weak)",
                                          ifelse(abs(corLast$estimate)<.6, " (moderate)", " (strong)"))))
)


```

##3. Syllable analysis
###Syllable performance by options
####Child accuracy on the syllable structure of token A (the correct answer). Compare the syllable structure by options to see children's accuracy in 2- or 3-option questions.
```{r, echo = F}
# Count the number of total presentations for each syllable structure
# Check the difficulty and learnability of each of the presented syllable structures
#UASdata.syllable <- UASdata.tokenid.ALLtokens %>%
UASdata.syllable <- UASdata.tokenid %>%
  ungroup() %>%
  group_by(token_a_syllable_structure, options) %>%
  summarise(
    presentations = sum(presentations,na.rm=TRUE),
    FirstAcc = round(mean(FirstAcc,na.rm=TRUE),2),
    LastAcc = round(mean(LastAcc,na.rm=TRUE),2)
  )

datatable(
  UASdata.syllable, 
  extensions = 'FixedColumns',
  rownames = FALSE,
  options = list(
  scrollX = TRUE,
  scrollCollapse = TRUE
))
```

###Syllable structure and token difficulty
####Breakdown of syllables experienced by children. The percent under each syllable structure indicates the percent of the attempts that include that structure.
```{r, echo = F}
UASdata.tokenid$token_a_syllable_structure = as.factor(UASdata.tokenid$token_a_syllable_structure)
UASdata.tokenid$token_a_syllable_structure <- relevel(UASdata.tokenid$token_a_syllable_structure,'CVC')
#unique(UASdata.tokenid$token_a_syllable_structure)
round(prop.table(table(UASdata.tokenid$token_a_syllable_structure)),2)

```

####A basic linear regression of first attempt ~ syllableStructure and last attempt ~ syllableStructure, with both weighted by the number of presentations. The first attempt includes 2- and 3-option questions, whereas the last attempt includes only 3-option questions. 
####{.tabset}
#####First attempt
```{r, echo = F}
# Perform ANOVA to determine whether syllable structures significantly differ from each other in first-attempt accuracy
#TODO do I use zFirstAcc or FirstAcc? z is z score, right?
syllable_effect_F <- lm(FirstAcc~token_a_syllable_structure,UASdata.tokenid,weight=UASdata.tokenid$presentations)
anova(syllable_effect_F)
```

#####Last attempt
```{r, echo = F}
# Perform ANOVA to determine whether syllable structures significantly differ from each other in last-attempt accuracy
syllable_effect_L <- lm(LastAcc~token_a_syllable_structure,UASdata.tokenid_3,weight=UASdata.tokenid_3$presentations)
anova(syllable_effect_L)
```

<!-- # ```{r} -->
<!-- # summary(lmer(UAS.correct ~ UAS.unit_id + cmsQuestions.difficulty_level_token + cmsQuestions.difficulty_level_trial + (1|treccId_phoneId), data = UASdata)) -->
<!-- #  -->
<!-- # ``` -->

##4. Token Type Analysis

###Does token type significantly affect the token difficulty?
####List the proportion of current token types
```{r, echo = F}
UASdata.tokenid$token_a_type = as.factor(UASdata.tokenid$token_a_type)
round(prop.table(table(UASdata.tokenid$token_a_type)),2)
message("note: 1 = word; 2 = syllable; 3 = phoneme")
```

####A basic linear regression of first attempt ~ tokenType and last attempt ~ tokenType, with both weighted by the number of presentations. The first attempt includes 2- and 3-option questions, whereas the last attempt includes only 3-option questions. 
####{.tabset}
#####First attempt
```{r, echo = F}
# Perform ANOVA to determine whether token structures significantly differ from each other in first-attempt accuracy
#TODO do I use zFirstAcc or FirstAcc? z is z score, right?
token_effect_F <- lm(FirstAcc~token_a_type,UASdata.tokenid,weight=UASdata.tokenid$presentations)
summary(token_effect_F)

sig_result = data.frame(summary(token_effect_F)$coef[summary(token_effect_F)$coef[,c(4)] <= .05, c(1,4)])
colnames(sig_result) [1] <- "coefficient"
colnames(sig_result) [2] <- "p_value"
sig_result$coefficient = NULL
sig_result$p_value = NULL

message(
  paste0("\n","percent of variance explained by the model: ", round(summary(token_effect_F)$r.squared,3)),"\n"
  #paste0("significant model terms printed below:")
)

#sig_result


```

#####Last attempt
```{r, echo = F}
# Perform ANOVA to determine whether syllable structures significantly differ from each other in last-attempt accuracy
token_effect_L <- lm(LastAcc~token_a_type,UASdata.tokenid_3,weight=UASdata.tokenid_3$presentations)
summary(token_effect_L)

sig_result = data.frame(summary(token_effect_L)$coef[summary(token_effect_L)$coef[,c(4)] <= .05, c(1,4)])
colnames(sig_result) [1] <- "coefficient"
colnames(sig_result) [2] <- "p_value"
sig_result$coefficient = NULL
sig_result$p_value = NULL

message(
  paste0("\n","percent of variance explained by the model: ", round(summary(token_effect_L)$r.squared,3)),"\n"
  #paste0("significant model terms printed below:")
)

#sig_result
```

##5. Unit 1 Analysis

###Who passed each question type or syllable type Unit 1?
####The tabs below display content for unit 1 and the attempts for each content area by error rate
```{r, echo = F}

#this makes the raw data one line for each attempt
UASdata_learningCurve_dataPrep = UASdata %>%
  select(treccId_phoneId, UAS.unit_id, cmsQuestions.trial_id, cmsQuestions.question_number, UAS.created_at, UAS.id, UAS.correct, syllable_structure_token_a, date, cmsQuestions.difficulty_level_trial) %>%
  #reverse the correctness column to get the error rate
  mutate(errorRate = 1-UAS.correct) %>%
  arrange(treccId_phoneId, cmsQuestions.trial_id, UAS.created_at) %>%
  group_by(treccId_phoneId, cmsQuestions.trial_id, cmsQuestions.question_number) %>%
  #add in trial opportunity
  mutate(opportunity_trial = row_number()) %>%
  arrange(treccId_phoneId, cmsQuestions.trial_id, opportunity_trial) %>%
  #calculate a rolling average of correct attempts across all attempts
  mutate(rollingErrorAverage_trial = cumsum(errorRate) / seq_along(opportunity_trial),
         promotionReady_trial = ifelse(max(opportunity_trial) > 100 |
                                      (rollingErrorAverage_trial <= .4 & opportunity_trial >= 15), 1, 0)) %>%
  ungroup() %>%
  #add in syllable opportunity
  arrange(treccId_phoneId, syllable_structure_token_a, UAS.created_at) %>%
  group_by(treccId_phoneId, syllable_structure_token_a) %>%
  mutate(opportunity_syllable = row_number()) %>%
  arrange(treccId_phoneId, syllable_structure_token_a, opportunity_trial) %>%
  mutate(rollingErrorAverage_syllable = cumsum(errorRate) / seq_along(opportunity_syllable),
         promotionReady_syllable = ifelse(max(opportunity_syllable) > 100 |
                                         (rollingErrorAverage_syllable <= .4 & opportunity_syllable >= 15), 1, 0)) %>%
  #add in difficulty opportunity
  arrange(treccId_phoneId, cmsQuestions.question_number, cmsQuestions.difficulty_level_trial, UAS.created_at) %>%
  group_by(treccId_phoneId, cmsQuestions.question_number, cmsQuestions.difficulty_level_trial) %>%
  mutate(opportunity_trial_difficulty = row_number()) %>%
  arrange(treccId_phoneId, cmsQuestions.question_number, cmsQuestions.difficulty_level_trial, opportunity_trial_difficulty) %>%
  mutate(rollingErrorAverage_trial_difficulty = cumsum(errorRate) / seq_along(opportunity_trial_difficulty),
         promotionReady_trial_difficulty = ifelse(max(opportunity_trial_difficulty) > 100 |
                                         (rollingErrorAverage_trial_difficulty <= .4 & opportunity_trial_difficulty >= 15), 1, 0)) %>%
  #per user, find the max unit id to determine whether a user passed unit 1
  group_by(treccId_phoneId) %>%
  mutate(maxUnit = max(UAS.unit_id),
         passedTrial = as.character(ifelse(maxUnit > 1, 1, 0))) %>%
  ungroup() %>%
  group_by(UAS.unit_id, cmsQuestions.trial_id, opportunity_trial) %>%
  mutate(userCountPerOpportunity_trial = n_distinct(treccId_phoneId)) %>%
  group_by(UAS.unit_id, syllable_structure_token_a, opportunity_trial) %>%
  mutate(userCountPerOpportunity_syllable = n_distinct(treccId_phoneId)) %>%
  group_by(treccId_phoneId, UAS.unit_id, cmsQuestions.trial_id) %>%
  mutate(passedTrial = ifelse(sum(promotionReady_trial)>0,1,0)) %>%
  group_by(treccId_phoneId, UAS.unit_id, syllable_structure_token_a) %>%
  mutate(passedSyllable = ifelse(sum(promotionReady_syllable)>0,1,0))



#trial dataset for unit 1 only
UASdata_learningCurve_trial = UASdata_learningCurve_dataPrep %>%
  filter(UAS.unit_id == 1) %>%
  group_by(treccId_phoneId, passedTrial, cmsQuestions.trial_id) %>%
  summarize(maxOpportunity_trial = max(opportunity_trial))

#syllable dataset for unit 1 only
UASdata_learningCurve_syllable = UASdata_learningCurve_dataPrep %>%
  filter(UAS.unit_id == 1) %>%
  group_by(treccId_phoneId, passedSyllable, syllable_structure_token_a) %>%
  summarize(maxOpportunity_syllable = max(opportunity_syllable))

# #uncomment this to create the trial table below.
# UASdata_trial_unit1Promotion = UASdata_learningCurve_dataPrep %>%
#   filter(
#     passedTrial == 1,
#     UAS.unit_id == 1
#          ) %>%
#   arrange(treccId_phoneId, cmsQuestions.trial_id, opportunity_trial) %>%
#   mutate(promotionPoint_trial = ifelse(treccId_phoneId == lag(treccId_phoneId) & cmsQuestions.trial_id == lag(cmsQuestions.trial_id) & promotionReady_trial == 1 & lag(promotionReady_trial == 0),1,0)) %>%
#   filter(promotionPoint_trial == 1) %>%
#   mutate(falsePromotion = ifelse(treccId_phoneId == lag(treccId_phoneId) & cmsQuestions.trial_id == lag(cmsQuestions.trial_id),1,0)) %>%
#   filter(falsePromotion != 1)
# 
# UASdata_unit1Promotion_trial_table = UASdata_unit1Promotion %>%
#   group_by(UAS.unit_id, cmsQuestions.trial_id) %>%
#   summarize(avgAttemptBeforePromotion = round(mean(opportunity_trial),2),
#             sdAttemptsBeforePromotion = round(sd(opportunity_trial),2),
#             avgMastery = round(mean(rollingAverage_trial),2),
#             sdMastery = round(sd(rollingAverage_trial),2),
#             nStudents = n_distinct(treccId_phoneId))
# 
# datatable(
#   UASdata_unit1Promotion_trial_table,
#   rownames = FALSE,
#   filter = "top",
#   extensions = 'FixedColumns',
#   options = list(
#   scrollX = TRUE,
#   scrollCollapse = TRUE
# ))

#TRIAL this makes the raw data one line for each student opportunity
UASdata_learningCurve_trial_oneLinePerStudentOpp = UASdata_learningCurve_dataPrep %>%
  group_by(passedTrial, treccId_phoneId, cmsQuestions.trial_id, UAS.unit_id, opportunity_trial, date, cmsQuestions.difficulty_level_trial) %>%
  summarize(errorRate_trial = mean(rollingErrorAverage_trial)
            #userCountPerOpportunity_trial = n_distinct(treccId_phoneId)
            ) %>%
  ungroup()

#TRIAL this makes the raw data one line for each opportunity (collapses students)
UASdata_learningCurve_trial_oneLinePerOpp = UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  #group_by(passedTrial, treccId_phoneId, cmsQuestions.trial_id, UAS.unit_id, opportunity_trial) %>%
  #summarize(errorRate_trial = mean(errorRate)) %>%
  group_by(passedTrial, cmsQuestions.trial_id, UAS.unit_id, opportunity_trial) %>%
  summarize(errorRate_trial = mean(errorRate_trial),
            userCountPerOpportunity_trial = n_distinct(treccId_phoneId)) %>%
  mutate(percentUsers = userCountPerOpportunity_trial/max(userCountPerOpportunity_trial)) %>%
  filter(percentUsers >= .1) %>%
  ungroup()


#TRIAL DIFFICULTY this makes the raw data one line for each student opportunity
UASdata_learningCurve_trialDifficulty_oneLinePerStudentOpp = UASdata_learningCurve_dataPrep %>%
  group_by(passedTrial, treccId_phoneId, cmsQuestions.trial_id, cmsQuestions.difficulty_level_trial, UAS.unit_id, opportunity_trial_difficulty, date) %>%
  summarize(errorRate_trialDifficulty = mean(rollingErrorAverage_trial_difficulty)
            #userCountPerOpportunity_trial = n_distinct(treccId_phoneId)
            ) %>%
  ungroup()


#SYLLABLE this makes the raw data one line for each student opportunity
UASdata_learningCurve_syllable_oneLinePerStudentOpp = UASdata_learningCurve_dataPrep %>%
  group_by(passedSyllable, treccId_phoneId, syllable_structure_token_a, UAS.unit_id, opportunity_syllable) %>%
  summarize(errorRate_syllable = mean(rollingErrorAverage_syllable)
            #userCountPerOpportunity_syllable = n_distinct(treccId_phoneId)
            ) %>%
  ungroup()

#SYLLABLE this makes the raw data one line for each opportunity (collapses students)
UASdata_learningCurve_syllable_oneLinePerOpp = UASdata_learningCurve_syllable_oneLinePerStudentOpp %>%
  #group_by(passedTrial, treccId_phoneId, cmsQuestions.syllable_id, UAS.unit_id, opportunity_syllable) %>%
  #summarize(errorRate_syllable = mean(errorRate)) %>%
  group_by(passedSyllable, syllable_structure_token_a, UAS.unit_id, opportunity_syllable) %>%
  summarize(errorRate_syllable = mean(errorRate_syllable),
            userCountPerOpportunity_syllable = n_distinct(treccId_phoneId)) %>%
  mutate(percentUsers = userCountPerOpportunity_syllable/max(userCountPerOpportunity_syllable)) %>%
  filter(percentUsers >= .1) %>%
  ungroup()

# #SYLLABLE this makes the raw data one line for each opportunity
# UASdata_learningCurve_syllable_oneLinePerOpp = UASdata_learningCurve_dataPrep %>%
#   #select(treccId_phoneId, UAS.unit_id, cmsQuestions.trial_id, UAS.created_at, UAS.id, UAS.correct) %>%
#   #arrange(treccId_phoneId, cmsQuestions.trial_id, UAS.created_at) %>%
#   group_by(passedTrial, treccId_phoneId, syllable_structure_token_a, UAS.unit_id, opportunity_syllable) %>%
#   mutate(errorRate_syllable = mean(rollingAverage_syllable)) %>%
#   group_by(passedTrial, syllable_structure_token_a, UAS.unit_id, opportunity_syllable) %>%
#   summarize(errorRate_syllable = mean(errorRate_syllable),
#             userCountPerOpportunity_syllable = n_distinct(treccId_phoneId)) %>%
#   mutate(percentUsers = userCountPerOpportunity_syllable/max(userCountPerOpportunity_syllable)) %>%
#   filter(percentUsers >= .1) %>%
#   ungroup()



```


###Average Opportunity Counts
####Question performance
####{.tabset}
#####Unit 1 Question 1
```{r, echo = F}
UASdata_learningCurve_trial_comparison = UASdata_learningCurve_trial %>%
  filter(cmsQuestions.trial_id == 1)
  
t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial) # where y is numeric and x is a binary factor

message(
  paste0(
    paste0("Result: ",
         ifelse(t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass trial 1.","No significant difference between children who passed / did not pass trial 1.")), "\n","\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children not passing trial 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2)),"\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children passing trial 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2))
    )
  )

```


#####Unit 1 Question 3
```{r, echo = F}
UASdata_learningCurve_trial_comparison = UASdata_learningCurve_trial %>%
  filter(cmsQuestions.trial_id == 3)
  
t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial) # where y is numeric and x is a binary factor

message(
  paste0(
    paste0("Result: ",
         ifelse(t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children not passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2)),"\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2))
  )
)

```


#####Unit 1 Question 5
```{r, echo = F}
UASdata_learningCurve_trial_comparison = UASdata_learningCurve_trial %>%
  filter(cmsQuestions.trial_id == 5)
  
t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial) # where y is numeric and x is a binary factor

message(
  paste0(
    paste0("Result: ",
         ifelse(t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children not passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2)),"\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2))
  )
)

```


#####Unit 1 Question 7
```{r, echo = F}
UASdata_learningCurve_trial_comparison = UASdata_learningCurve_trial %>%
  filter(cmsQuestions.trial_id == 7)
  
t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial) # where y is numeric and x is a binary factor

message(
  paste0(
    paste0("Result: ",
         ifelse(t.test(UASdata_learningCurve_trial_comparison$maxOpportunity_trial~UASdata_learningCurve_trial_comparison$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children not passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 0]),2)),"\n",
    paste0("avg opportunity count on question ", unique(UASdata_learningCurve_trial_comparison$cmsQuestions.trial_id), " for children passing unit 1: ", round(mean(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2),". SD = ", round(sd(UASdata_learningCurve_trial_comparison$maxOpportunity_trial[UASdata_learningCurve_trial_comparison$passedTrial == 1]),2))
  )
)
```


<!-- ####Syllable performance -->
<!-- ###{.tabset} -->
<!-- ####Unit 1 CCV -->
<!-- ```{r, echo = F} -->
<!-- UASdata_learningCurve_syllable_comparison = UASdata_learningCurve_syllable %>% -->
<!--   filter(syllable_structure_token_a == "CCV") -->

<!-- #t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$pass#edSyllable) # where y is numeric and x is a binary factor -->

<!-- message( -->
<!--   paste0( -->
<!--     paste0("Result: ", -->
<!--          ifelse(t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass CCV.","No significant difference between children who passed / did not pass CCV.")), "\n","\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children not passing CCV = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2)),"\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children passing CCV = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2)) -->
<!--   ) -->
<!-- ) -->

<!-- ``` -->


<!-- ####Unit 1 CCVC -->
<!-- ```{r, echo = F} -->
<!-- UASdata_learningCurve_syllable_comparison = UASdata_learningCurve_syllable %>% -->
<!--   filter(syllable_structure_token_a == "CCVC") -->

<!-- #t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$pass#edSyllable) # where y is numeric and x is a binary factor -->

<!-- message( -->
<!--   paste0( -->
<!--     paste0("Result: ", -->
<!--          ifelse(t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass CCVC.","No significant difference between children who passed / did not pass CCVC.")), "\n","\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children not passing CCVC = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2)),"\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children passing CCVC = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2)) -->
<!--   ) -->
<!-- ) -->
<!-- ``` -->
<!-- ####Unit 1 CV -->
<!-- ```{r, echo = F} -->
<!-- UASdata_learningCurve_syllable_comparison = UASdata_learningCurve_syllable %>% -->
<!--   filter(syllable_structure_token_a == "CV") -->

<!-- t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable) # where y is numeric and x is a binary factor -->

<!-- message( -->
<!--   paste0( -->
<!--     paste0("Result: ", -->
<!--          ifelse(t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children not passing CV = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2)),"\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children passing CV = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2)) -->
<!--   ) -->
<!-- ) -->
<!-- ``` -->


<!-- ####Unit 1 CVC -->
<!-- ```{r, echo = F} -->
<!-- UASdata_learningCurve_syllable_comparison = UASdata_learningCurve_syllable %>% -->
<!--   filter(syllable_structure_token_a == "CVC") -->

<!-- t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable) # where y is numeric and x is a binary factor -->

<!-- message( -->
<!--   paste0( -->
<!--     paste0("Result: ", -->
<!--          ifelse(t.test(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable~UASdata_learningCurve_syllable_comparison$passedSyllable)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children not passing CVC = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 0]),2)),"\n", -->
<!--     paste0("avg opportunity count on syllable ", unique(UASdata_learningCurve_syllable_comparison$syllable_structure_token_a), " for children passing CVC = ", round(mean(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2),"; SD = ", round(sd(UASdata_learningCurve_syllable_comparison$maxOpportunity_syllable[UASdata_learningCurve_syllable_comparison$passedSyllable == 1]),2)) -->
<!--   ) -->
<!-- ) -->
<!-- ``` -->


<!-- <!-- ###Regressions --> -->
<!-- <!-- ```{r, echo = F} --> -->
<!-- <!-- UASdata_learningCurve_trial_oneLinePerOpp_1 = UASdata_learningCurve_trial_oneLinePerOpp %>% --> -->
<!-- <!--   filter(UAS.unit_id == 1) --> -->

<!-- <!-- names(UASdata_learningCurve_trial_oneLinePerOpp_1) --> -->

<!-- <!-- UASdata_learningCurve_trial_oneLinePerOpp_1$opportunity_trial = as.factor(UASdata_learningCurve_trial_oneLinePerOpp_1$opportunity_trial) --> -->
<!-- <!-- UASdata_learningCurve_trial_oneLinePerOpp_1$cmsQuestions.trial_id = as.factor(UASdata_learningCurve_trial_oneLinePerOpp_1$cmsQuestions.trial_id) --> -->

<!-- <!-- summary(lm(passedTrial ~ cmsQuestions.trial_id + errorRate_trial + userCountPerOpportunity_trial, data = UASdata_learningCurve_trial_oneLinePerOpp_1)) --> -->

<!-- <!-- ``` --> -->

###Learning Curves (interactive)
####Data filtered for unit 1 content. The 0/1 facets in each plot represent students who did or did not pass that particular question or syllable.
###{.tabset}
####Question 1
```{r, echo = F}
#to plot each student
suppressMessages(
  suppressWarnings(
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 1
         #passedTrial == 1,
         #opportunity_trial <= 50
         ) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for Unit 1, Question 1") +
  labs(
    x = "opportunity count", 
    y = "rolling error rate", 
    col = "User"
    ) +
  geom_line() +
  facet_wrap(~ passedTrial, ncol = 2)
)
)
)

message(
  paste0("Students passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 1 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 1]),"\n"),
  paste0("Students not passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 0 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 1]))
)
```

####Question 3
```{r, echo = F}
#to plot each student
suppressMessages(
  suppressWarnings(
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 3
         #passedTrial == 1,
         #opportunity_trial <= 50
         ) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for Unit 1, Question 3") +
  labs(
    x = "opportunity count", 
    y = "rolling error rate", 
    col = "User"
    ) +
  geom_line() +
  facet_wrap(~ passedTrial, ncol = 2)
)
)
)

message(
  paste0("Students passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 1 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 3]),"\n"),
  paste0("Students not passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 0 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 3]))
)
```

####Question 5
```{r, echo = F}
#to plot each student
suppressMessages(
  suppressWarnings(
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 5
         #passedTrial == 1,
         #opportunity_trial <= 50
         ) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for Unit 1, Question 5") +
  labs(
    x = "opportunity count", 
    y = "rolling error rate", 
    col = "User"
    ) +
  geom_line() +
  facet_wrap(~ passedTrial, ncol = 2)
)
)
)

message(
  paste0("Students passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 1 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 5]),"\n"),
  paste0("Students not passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 0 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 5]))
)
```

####Question 7
```{r, echo = F}
#to plot each student
suppressMessages(
  suppressWarnings(
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 7
         #opportunity_trial <= 50
         ) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for Unit 1, Question 7") +
  labs(
    x = "opportunity count", 
    y = "rolling error rate", 
    col = "User"
    ) +
  geom_line() +
  facet_wrap(~ passedTrial, ncol = 2)
)
)
)

message(
  paste0("Students passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 1 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 7]),"\n"),
  paste0("Students not passing this question: ", n_distinct(UASdata_learningCurve_trial_oneLinePerStudentOpp$treccId_phoneId[UASdata_learningCurve_trial_oneLinePerStudentOpp$passedTrial == 0 & UASdata_learningCurve_trial_oneLinePerStudentOpp$cmsQuestions.trial_id == 7]))
)
```

###Error curves with smoothing
###{.tabset}
####Question 1
```{r, echo = F}

#to plot each student with the rolling average
suppressWarnings({
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 1
         #passedTrial == 1
         #opportunity_trial <= 50
         ) %>%
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #group = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 1") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  geom_smooth(se=FALSE) +
  facet_wrap(~ passedTrial, ncol = 2)
)
})

```

####Question 3
```{r, echo = F}

#to plot each student with the rolling average
suppressWarnings({
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 3
         #opportunity_trial <= 50
         ) %>%
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #group = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 3") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  geom_smooth(se = FALSE) +
  facet_wrap(~ passedTrial, ncol = 2)
)
})

```

####Question 5
```{r, echo = F}

#to plot each student with the rolling average
suppressWarnings({
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 5
         ) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId,
      group = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  #ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 5") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  geom_smooth(se = FALSE) +
  facet_wrap(~ passedTrial, ncol = 2)
)
})

```


####Question 7
```{r, echo = F}

#to plot each student with the rolling average
suppressWarnings({
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 7
         #opportunity_trial <= 50
         ) %>%
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      col = treccId_phoneId
      #group = treccId_phoneId
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 7") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  geom_smooth(se = F) +
  facet_wrap(~ passedTrial, ncol = 2)
)
})

```

###Error curves with smoothing (difficulty)
###{.tabset}
####Question 1
```{r, echo = F}
# suppressWarnings({
# ggplotly(
test = UASdata_learningCurve_trialDifficulty_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 1
         #opportunity_trial <= 50
         )
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%

ggplot(test, 
    aes(
      x = opportunity_trial_difficulty,
      y = errorRate_trialDifficulty,
      col = passedTrial,
      group = passedTrial
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 1") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  stat_smooth(se = F) +
  facet_wrap(~ cmsQuestions.difficulty_level_trial, ncol = 2)
# )
# })

```

####Question 3
```{r, echo = F}
# suppressWarnings({
# ggplotly(
test = UASdata_learningCurve_trialDifficulty_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 3
         #opportunity_trial <= 50
         )
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%

ggplot(test, 
    aes(
      x = opportunity_trial_difficulty,
      y = errorRate_trialDifficulty,
      col = passedTrial,
      group = passedTrial
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 3") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  stat_smooth(se = F) +
  facet_wrap(~ cmsQuestions.difficulty_level_trial, ncol = 2)
# )
# })

```


####Question 5
```{r, echo = F}
# suppressWarnings({
# ggplotly(
test = UASdata_learningCurve_trialDifficulty_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 5
         #opportunity_trial <= 50
         )
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%

ggplot(test, 
    aes(
      x = opportunity_trial_difficulty,
      y = errorRate_trialDifficulty,
      col = passedTrial,
      group = passedTrial
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 5") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  stat_smooth(se = F) +
  facet_wrap(~ cmsQuestions.difficulty_level_trial, ncol = 2)
# )
# })

```

####Question 7
```{r, echo = F}
# suppressWarnings({
# ggplotly(
test = UASdata_learningCurve_trialDifficulty_oneLinePerStudentOpp %>%
  group_by(treccId_phoneId) %>%
  filter(UAS.unit_id == 1,
         cmsQuestions.trial_id == 7
         #opportunity_trial <= 50
         )
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%

ggplot(test, 
    aes(
      x = opportunity_trial_difficulty,
      y = errorRate_trialDifficulty,
      col = passedTrial,
      group = passedTrial
      #label = userCountPerOpportunity_trial
      )
    ) +
  ylim(0, 1.1) +
  ggtitle("Error rate curves for Unit 1, Question 7") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  stat_smooth(se = F) +
  facet_wrap(~ cmsQuestions.difficulty_level_trial, ncol = 2)
# )
# })

```

###curve classification
###{.tabset}
####Question 1

```{r, echo = F, width = 10}
#also to plot each student
xxx = UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1,
         #opportunity_trial <= 10,
         cmsQuestions.trial_id == 1) %>%
  group_by(treccId_phoneId) %>% 
    do(cbind(.,slope=unname(coef(lm(errorRate_trial~opportunity_trial, .))[2]))) %>% 
    mutate(slopesign=ifelse(slope > 0.1, "positive",ifelse(slope < -0.1, "negative", "flat"))) %>%
  ungroup() %>%
  filter(!is.na(slopesign))
  #       slopesign != "flat")

ggplotly(
ggplot(xxx, aes(opportunity_trial,errorRate_trial, color=factor(treccId_phoneId), group=treccId_phoneId)) +
  geom_line(method = "lm") + 
  ylim(0,1.05) +
  ggtitle("Error rate curves for Unit 1, Question 1") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  facet_wrap(~slopesign, ncol = 3) +
  theme(legend.position="none")
)

```

####Question 3
```{r, echo = F, width = 10}
#also to plot each student
xxx = UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1,
         #opportunity_trial <= 10,
         cmsQuestions.trial_id == 3) %>%
  group_by(treccId_phoneId) %>% 
    do(cbind(.,slope=unname(coef(lm(errorRate_trial~opportunity_trial, .))[2]))) %>% 
    mutate(slopesign=ifelse(slope > 0.1, "positive",ifelse(slope < -0.1, "negative", "flat"))) %>%
  ungroup() %>%
  filter(!is.na(slopesign))
  #       slopesign != "flat")

ggplotly(
ggplot(xxx, aes(opportunity_trial,errorRate_trial, color=factor(treccId_phoneId), group=treccId_phoneId)) +
  geom_line(method = "lm") + 
  ylim(0,1.05) +
  ggtitle("Error rate curves for Unit 1, Question 3") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  facet_wrap(~slopesign, ncol = 3) +
  theme(legend.position="none")
)

```


####Question 5
```{r, echo = F, width = 10}
#also to plot each student
xxx = UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1,
        # opportunity_trial <= 10,
         cmsQuestions.trial_id == 5) %>%
  group_by(treccId_phoneId) %>% 
    do(cbind(.,slope=unname(coef(lm(errorRate_trial~opportunity_trial, .))[2]))) %>% 
    mutate(slopesign=ifelse(slope > 0.1, "positive",ifelse(slope < -0.1, "negative", "flat"))) %>%
  ungroup() %>%
  filter(!is.na(slopesign))
  #       slopesign != "flat")

ggplotly(
ggplot(xxx, aes(opportunity_trial,errorRate_trial, color=factor(treccId_phoneId), group=treccId_phoneId)) +
  geom_line(method = "lm") + 
  ylim(0,1.05) +
  ggtitle("Error rate curves for Unit 1, Question 5") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  facet_wrap(~slopesign, ncol = 3) +
  theme(legend.position="none")
)

```


####Question 7
```{r, echo = F, width = 10}
#also to plot each student
xxx = UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1,
        # opportunity_trial <= 10,
         cmsQuestions.trial_id == 7) %>%
  group_by(treccId_phoneId) %>% 
    do(cbind(.,slope=unname(coef(lm(errorRate_trial~opportunity_trial, .))[2]))) %>% 
    mutate(slopesign=ifelse(slope > 0.1, "positive",ifelse(slope < -0.1, "negative", "flat"))) %>%
  ungroup() %>%
  filter(!is.na(slopesign))
  #       slopesign != "flat")

ggplotly(
ggplot(xxx, aes(opportunity_trial,errorRate_trial, color=factor(treccId_phoneId), group=treccId_phoneId)) +
  geom_line(method = "lm") + 
  ylim(0,1.05) +
  ggtitle("Error rate curves for Unit 1, Question 7") +
  labs(
    x = "opportunity count",
    y = "rolling error rate",
    col = "User"
    ) +
  facet_wrap(~slopesign, ncol = 3) +
  theme(legend.position="none")
)

```


###average error rate across students, smoothing
```{r, echo = F}
# plot for one opportunity per student, with an average error performance per user
suppressMessages(
ggplotly(
UASdata_learningCurve_trial_oneLinePerStudentOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1) %>%
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%
  ggplot(
    aes(
      x = opportunity_trial,
      y = errorRate_trial,
      group = passedTrial,
      col = as.factor(passedTrial)
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for each trial structure in Unit 1") +
  labs(
    x = "opportunity count", 
    y = "avg error rate", 
    col = "Passed\nTrial"
    ) +
  geom_smooth() +
    #aes(text = paste0("children at opportunity count ",opportunity, ": ",n_distinct(treccId_phoneId[UASdata_learningCurve_trial$opportunity == opportunity])))
  facet_wrap(~ cmsQuestions.trial_id, ncol = 2)
  #ggplotly(tooltip = "text")
)
)


```


<!-- #### by trials (survival curve) -->
<!-- ```{r, echo = F} -->

<!-- suppressMessages( -->
<!-- ggplotly( -->
<!-- UASdata_learningCurve_trial_oneLinePerOpp %>% -->
<!--   ungroup() %>% -->
<!--   #group_by(opportunity_trial, passedTrial) %>% -->
<!--   filter(UAS.unit_id == 1) %>% -->
<!--          #userCountPerOpportunity >= 10) %>% -->
<!--          #opportunity <= 50) %>% -->
<!--   ggplot( -->
<!--     aes( -->
<!--       x = opportunity_trial, -->
<!--       y = userCountPerOpportunity_trial, -->
<!--       col = passedTrial -->
<!--       #label = userCountPerOpportunity_trial -->
<!--       ) -->
<!--     ) + -->
<!--   #ylim(0, 1) + -->
<!--   ggtitle("Survival curves for each trial in Unit 1") + -->
<!--   labs( -->
<!--     x = "opportunity count",  -->
<!--     y = "user count",  -->
<!--     col = "passed\nunit 1") + -->
<!--   stat_smooth() + -->
<!--     #aes(text = paste0("children at opportunity count ",opportunity, ": ",n_distinct(treccId_phoneId[UASdata_learningCurve_trial$opportunity == opportunity]))) -->
<!--   facet_wrap(~ cmsQuestions.trial_id, ncol = 2) -->
<!--   #ggplotly(tooltip = "text") -->
<!-- ) -->
<!-- ) -->


<!-- ``` -->

####by syllables (plot)
```{r, echo = F}
# #ggplotly(
# UASdata_learningCurve_trial %>%
#   filter(UAS.unit_id == 1,
#          userCountPerOpportunity >= 10) %>%
#          #opportunity <= 50) %>%
#   ggplot(aes(x = opportunity,
#              y = errorRate,
#              col = passedTrial
#              )) +
#   ylim(0, 1) +
#   labs(x = "opportunity count", y = "avg error rate") +
#   facet_wrap(~ cmsQuestions.trial_id, ncol = 2) +
#   #geom_smooth()
#   geom_smooth(
#     #aes(text = paste0('n_students: ', userCountPerOpportunity))
#     )
#   #                                         '<br>',
#   #                                         'read: ',,
# #)

suppressMessages(
ggplotly(
UASdata_learningCurve_syllable_oneLinePerOpp %>%
  ungroup() %>%
  filter(UAS.unit_id == 1) %>%
         #userCountPerOpportunity >= 10) %>%
         #opportunity <= 50) %>%
  ggplot(
    aes(
      x = opportunity_syllable,
      y = errorRate_syllable,
      col = as.factor(passedSyllable),
      group = passedSyllable
      )
    ) +
  ylim(0, 1) +
  ggtitle("Error rate curves for each syllable structure in Unit 1") +
  labs(
    x = "opportunity count", 
    y = "avg error rate", 
    col = "passed\nsyllable"
    ) +
  geom_smooth() +
    #aes(text = paste0("children at opportunity count ",opportunity, ": ",n_distinct(treccId_phoneId[UASdata_learningCurve_trial$opportunity == opportunity])))
  facet_wrap(~ syllable_structure_token_a, ncol = 2)
  #ggplotly(tooltip = "text")
)
)

```

<!-- #### by syllables (survival curve) -->
<!-- ```{r, echo = F} -->
<!-- suppressMessages( -->
<!-- ggplotly( -->
<!-- UASdata_learningCurve_syllable_oneLinePerOpp %>% -->
<!--   ungroup() %>% -->
<!--   #group_by(opportunity_trial, passedTrial) %>% -->
<!--   filter(UAS.unit_id == 1) %>% -->
<!--          #userCountPerOpportunity >= 10) %>% -->
<!--          #opportunity <= 50) %>% -->
<!--   ggplot( -->
<!--     aes( -->
<!--       x = opportunity_syllable, -->
<!--       y = userCountPerOpportunity_syllable, -->
<!--       col = passedTrial -->
<!--       #label = userCountPerOpportunity_trial -->
<!--       ) -->
<!--     ) + -->
<!--   #ylim(0, 1) + -->
<!--   ggtitle("Survival curves for each syllable in Unit 1") + -->
<!--   labs( -->
<!--     x = "opportunity count",  -->
<!--     y = "user count",  -->
<!--     col = "passed\nunit 1") + -->
<!--   stat_smooth() + -->
<!--     #aes(text = paste0("children at opportunity count ",opportunity, ": ",n_distinct(treccId_phoneId[UASdata_learningCurve_trial$opportunity == opportunity]))) -->
<!--   facet_wrap(~ syllable_structure_token_a, ncol = 2) -->
<!--   #ggplotly(tooltip = "text") -->
<!-- ) -->
<!-- ) -->


<!-- ``` -->

###Passing / Not Passing Unit 1
####Across all of the following factors for Unit 1, are there significant usage differences between students who did and did not pass Unit 1?

###Question Type
###{.tabset}
####Attempts per question type
```{r, echo = F}

#for unit 1 questions only
attPerQuestionType = as_tibble(UASdata_learningCurve_trial) %>%
  group_by(treccId_phoneId, 
           passedTrial, 
           cmsQuestions.trial_id) %>%
  summarize(attempts = max(maxOpportunity_trial)) %>%
  group_by(treccId_phoneId, 
           passedTrial) %>%
  summarize(avgQuestionTypeAttemptsPerStudent = mean(attempts))

#and run a t-test
t.test(attPerQuestionType$avgQuestionTypeAttemptsPerStudent~attPerQuestionType$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
attPerQuestionType %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = avgQuestionTypeAttemptsPerStudent, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Attempts Per Question Type")


message(
  paste0("Result: ",
         ifelse(t.test(attPerQuestionType$avgQuestionTypeAttemptsPerStudent~attPerQuestionType$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg attempts per question for children not passing Unit 1 = ", round(mean(attPerQuestionType$avgQuestionTypeAttemptsPerStudent[attPerQuestionType$passedTrial == 0]),2),"; SD = ", round(sd(attPerQuestionType$avgQuestionTypeAttemptsPerStudent[attPerQuestionType$passedTrial == 0]),2)),"\n",
    paste0("Avg attempts per question for children passing Unit 1 = ", round(mean(attPerQuestionType$avgQuestionTypeAttemptsPerStudent[attPerQuestionType$passedTrial == 1]),2),"; SD = ", round(sd(attPerQuestionType$avgQuestionTypeAttemptsPerStudent[attPerQuestionType$passedTrial == 1]),2))
  )
  )

```


####Difficulty per Question type [forthcoming]
```{r, echo = F}

```


###Lessons
###{.tabset}
####Correct questions per lesson
```{r, echo = F}

#for unit 1 questions only
questionsCorrectPerUser = as_tibble(UASdata) %>%
  group_by(treccId_phoneId, UAS.unit_id, UAS.lesson_id) %>%
  summarize(totalQuestionsCorrectPerLesson = sum(UAS.correct)) %>%
  group_by(treccId_phoneId) %>%
  mutate(maxUnit = max(UAS.unit_id),
         passedTrial = ifelse(UAS.unit_id == 1 & maxUnit != 1, 1, 0)) %>%
  filter(UAS.unit_id == 1) %>%
  group_by(treccId_phoneId, passedTrial) %>%
  summarize(avg_totalQuestionsCorrectPerLesson = mean(totalQuestionsCorrectPerLesson)) %>%
  ungroup()

#and run a t-test
t.test(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson~questionsCorrectPerUser$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
questionsCorrectPerUser %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = avg_totalQuestionsCorrectPerLesson, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Correct Questions Per Lesson")

message(
  paste0("Result: ",
         ifelse(t.test(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson~questionsCorrectPerUser$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg correct questions per lesson by children not passing Unit = ", round(mean(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson[questionsCorrectPerUser$passedTrial == 0]),2),"; SD = ", round(sd(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson[questionsCorrectPerUser$passedTrial == 0]),2)),"\n",
    paste0("Avg correct questions per lesson by children passing Unit 1 = ", round(mean(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson[questionsCorrectPerUser$passedTrial == 1]),2),"; SD =  ", round(sd(questionsCorrectPerUser$avg_totalQuestionsCorrectPerLesson[questionsCorrectPerUser$passedTrial == 1]),2))
  )
  )

```

####Number of lessons started
```{r, echo = F}

#for unit 1 questions only
lessonsAttemptedPerUser = as_tibble(UASdata) %>%
  group_by(treccId_phoneId, UAS.unit_id) %>%
  summarize(totalLessons = n_distinct(UAS.lesson_id)) %>%
  group_by(treccId_phoneId) %>%
  mutate(maxUnit = max(UAS.unit_id),
         passedTrial = ifelse(UAS.unit_id == 1 & maxUnit != 1, 1, 0)) %>%
  filter(UAS.unit_id == 1) %>%
  ungroup()

#and run a t-test
t.test(lessonsAttemptedPerUser$totalLessons~lessonsAttemptedPerUser$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
lessonsAttemptedPerUser %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = totalLessons, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Number of Lessons Started")

message(
  paste0("Result: ",
         ifelse(t.test(lessonsAttemptedPerUser$totalLessons~lessonsAttemptedPerUser$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg lessons started by children not passing Unit 1 = ", round(mean(lessonsAttemptedPerUser$totalLessons[lessonsAttemptedPerUser$passedTrial == 0]),2),"; SD = ", round(sd(lessonsAttemptedPerUser$totalLessons[lessonsAttemptedPerUser$passedTrial == 0]),2)),"\n",
    paste0("Avg lessons started by children passing Unit 1 = ", round(mean(lessonsAttemptedPerUser$totalLessons[lessonsAttemptedPerUser$passedTrial == 1]),2),"; SD =  ", round(sd(lessonsAttemptedPerUser$totalLessons[lessonsAttemptedPerUser$passedTrial == 1]),2))
  )
  )

```



###Calls
###{.tabset}
####Number of calls with attempted questions
```{r, echo = F}

#for unit 1 questions only
callsWithAttemptedQuestions = as_tibble(UASdata) %>%
  group_by(treccId_phoneId, UAS.unit_id) %>%
  summarize(totalCallsWithAttempts = n_distinct(cdr.uniqueId),
            totalCallsOverall = max(callNumber)) %>%
  group_by(treccId_phoneId) %>%
  mutate(maxUnit = max(UAS.unit_id),
         passedTrial = ifelse(UAS.unit_id == 1 & maxUnit != 1, 1, 0)) %>%
  filter(UAS.unit_id == 1)

#run a t-test
t.test(callsWithAttemptedQuestions$totalCallsWithAttempts~callsWithAttemptedQuestions$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
callsWithAttemptedQuestions %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = totalCallsWithAttempts, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Calls With Attempted Questions Per User")

# #plot the averages
# callsWithAttemptedQuestions %>%
#   group_by(passedTrial) %>%
#   ggplot() +
#   geom_bar(aes(x = as.factor(passedTrial), y = totalCallsWithAttempts, group = as.factor(passedTrial)),
#            position = "dodge", stat = "summary", fun.y = "mean") +
#   #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
#   labs(x = "Passed Unit 1", y = "Avg Calls Per User")

message(
  paste0("Result: ",
         ifelse(t.test(callsWithAttemptedQuestions$totalCallsWithAttempts~callsWithAttemptedQuestions$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg calls (with question attempts) by children not passing Unit 1 = ", round(mean(callsWithAttemptedQuestions$totalCallsWithAttempts[callsWithAttemptedQuestions$passedTrial == 0]),2),"; SD = ", round(sd(callsWithAttemptedQuestions$totalCallsWithAttempts[callsWithAttemptedQuestions$passedTrial == 0]),2)),"\n",
    paste0("Avg calls (with question attempts) by children passing Unit 1 = ", round(mean(callsWithAttemptedQuestions$totalCallsWithAttempts[callsWithAttemptedQuestions$passedTrial == 1]),2),"; SD = ", round(sd(callsWithAttemptedQuestions$totalCallsWithAttempts[callsWithAttemptedQuestions$passedTrial == 1]),2))
  )
  )

```


####Calls with questions per active use days
```{r, echo = F}

callDuration = as_tibble(UASdata) %>%
  group_by(treccId_phoneId, UAS.unit_id, cdr.uniqueId) %>%
  filter(UAS.unit_id == 1) %>%
  summarize(durationCall = unique(billsec)) %>%
  group_by(treccId_phoneId, UAS.unit_id) %>%
  summarize(avgCallDuration = mean(durationCall)) %>%
  mutate(UAS.unit_id = NULL)

#for unit 1 questions only
callsPerActiveDaysWithAttemptedQuestions = as_tibble(UASdata) %>%
  group_by(treccId_phoneId, UAS.unit_id) %>%
  summarize(totalCalls = n_distinct(cdr.uniqueId),
            totalActiveDays = n_distinct(date),
            totalRangeDays = as.numeric(max(date) - min(date) +1)
            ) %>%
  group_by(treccId_phoneId) %>%
  mutate(maxUnit = max(UAS.unit_id),
         passedTrial = ifelse(UAS.unit_id == 1 & maxUnit != 1, 1, 0),
         callsPerActiveDays = totalCalls / totalActiveDays,
         callsPerAllDays = totalCalls / totalRangeDays) %>%
  filter(UAS.unit_id == 1) %>%
  left_join(callDuration, by = c("treccId_phoneId"))

#and run a t-test
t.test(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays~callsPerActiveDaysWithAttemptedQuestions$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
callsPerActiveDaysWithAttemptedQuestions %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = callsPerActiveDays, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
labs(x = "Passed Unit 1", y = "Avg Calls During Active Days \n(with Attempted Questions) Per User")

message(
  paste0("Result: ",
         ifelse(t.test(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays~callsPerActiveDaysWithAttemptedQuestions$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg calls per active days (with question attempts) by children not passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2),"; SD = ", round(sd(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2)),"\n",
    paste0("Avg calls per active days (with question attempts) by children passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2),"; SD = ", round(sd(callsPerActiveDaysWithAttemptedQuestions$callsPerActiveDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2))
  )
  )

```

####Calls with questions per range days
```{r, echo = F}

#and run a t-test
t.test(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays~callsPerActiveDaysWithAttemptedQuestions$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
callsPerActiveDaysWithAttemptedQuestions %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = callsPerAllDays, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Calls During Days Between First / \nLast Call (with question attempts) Per User")

message(
  paste0("Result: ",
         ifelse(t.test(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays~callsPerActiveDaysWithAttemptedQuestions$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg calls in call date range (with question attempts) by children not passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2),"; SD = ", round(sd(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2)),"\n",
    paste0("Avg calls in call date range (with question attempts) by children passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2),"; SD =  ", round(sd(callsPerActiveDaysWithAttemptedQuestions$callsPerAllDays[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2))
  )
  )

```
####Call duration
```{r, echo = F}

#and run a t-test
t.test(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration~callsPerActiveDaysWithAttemptedQuestions$passedTrial) # where y is numeric and x is a binary factor

#plot the averages
callsPerActiveDaysWithAttemptedQuestions %>%
  group_by(passedTrial) %>%
  ggplot() +
  geom_bar(aes(x = as.factor(passedTrial), y = avgCallDuration, group = as.factor(passedTrial)),
           position = "dodge", stat = "summary", fun.y = "mean") +
  #geom_errorbar(width = .1, aes(x = passedTrial, ymin = mean(totalCalls)-sd(totalCalls), ymax = mean(totalCalls)+sd(totalCalls)), inherit.aes = FALSE) +
  labs(x = "Passed Unit 1", y = "Avg Call Duration")

message(
  paste0("Result: ",
         ifelse(t.test(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration~callsPerActiveDaysWithAttemptedQuestions$passedTrial)[["p.value"]]< 0.05,"*Significant difference* between children who passed / did not pass Unit 1.","No significant difference between children who passed / did not pass Unit 1.")), "\n","\n",
  paste0(
    paste0("Avg calls in call date range (with question attempts) by children not passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2),"; SD = ", round(sd(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 0]),2)),"\n",
    paste0("Avg calls in call date range (with question attempts) by children passing Unit 1 = ", round(mean(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2),"; SD =  ", round(sd(callsPerActiveDaysWithAttemptedQuestions$avgCallDuration[callsPerActiveDaysWithAttemptedQuestions$passedTrial == 1]),2))
  )
  )

```

####Questions per call [forthcoming]
```{r, echo = F}


```

<!-- ####table -->
<!-- ```{r, echo = F} -->
<!-- datatable( -->
<!--   UASdata_learningCurve_trial %>% -->
<!--   filter(UAS.unit_id == 1, -->
<!--          userCountPerOpportunity >= 10), -->
<!--   rownames = FALSE, -->
<!--   filter = "top", -->
<!--   extensions = 'FixedColumns', -->
<!--   options = list( -->
<!--   scrollX = TRUE, -->
<!--   scrollCollapse = TRUE -->
<!-- )) -->

<!-- ``` -->


