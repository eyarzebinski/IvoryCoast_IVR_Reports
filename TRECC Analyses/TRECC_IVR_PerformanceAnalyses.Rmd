---
title: "TRECC IVR Performance Analyses"
author: "Evelyn Yarzebinski, Benjamin Zinszer, Mackenzie Campbell"
output:  "html_document"
---

##0. Metadata
```{r prep data, include = F}
#clean up environment
rm(list=ls())
gc(verbose=TRUE)

source("TRECC_dataPrep.R")
#source("TRECC_delawareCode.R")
```

###Report Generation
```{r report time, echo = F}
message(paste("report generated:",Sys.time(),sep=""))

```

###What is the min/max and span of the data?
####Note: Date shown here is the most recent day in the dataset and may be incomplete due to time of data export
```{r date range, echo = F}
UAS_maxDate = max(CIVdata_filter$date)
UAS_minDate = min(CIVdata_filter$date)
CDR_maxDate = max(cdrData_filter_IVRCall$date)
CDR_minDate = min(cdrData_filter_IVRCall$date)
UAS_nDays = UAS_maxDate - UAS_minDate + 1
CDR_nDays = CDR_maxDate - CDR_minDate + 1
message(paste("User Answer Data ranges from ", UAS_minDate," to ", UAS_maxDate,". The span is ",UAS_nDays," days.", sep = ""))
message(paste("CDR data ranges from ", CDR_minDate, " to ", CDR_maxDate,". The span is ",CDR_nDays," days.", sep = ""))
```

```{r saving, include=F}
#write.csv(CIVdata_filter,paste("~/Documents/IvoryCoast/data/CIVData_currentDataThrough_",UAS_maxDate,".csv",sep=""),row.names = FALSE)
#write.xlsx(CIVdata_filter,paste("~/Documents/IvoryCoast/data/CIVData_currentDataThrough_",UAS_mostRecentDate,".xlsx",sep=""),row.names = FALSE)
#write.csv(cdrData_filter,paste0("~/Documents/IvoryCoast/data/cdrData_currentDataThrough_",CDR_mostRecentDate,".csv"),row.names = FALSE)
#write.xlsx(cdrData_filter,paste("~/Documents/IvoryCoast/data/cdrData_currentDataThrough_",CDR_mostRecentDate,".xlsx",sep=""),row.names = FALSE)
```

###Explore the data
```{r Ben data exploration, echo = F}
datatable(CIVdata_filter.tokenid)
```



##1. Question Summary
###Exploratory tables
####Originally, these were called "question templates" and then became "VOS" (voice output structure) or even "question frames" - basically, the raw question structure that different tokens are plugged into.

####There should be 5 questions per lesson. In places where there are fewer than 5 average questions per lesson, we should confirm what is happening - is the student hanging up early? Are there indeed 5 questions per lesson? etc. For example, unit 4 question 1 has 7 lessons that have less than 5 questions, so this unit/question combination should be checked.

###{.tabset}
####Number of Questions Per Lesson
```{r questions per lesson, echo = F}
questionsPerLesson = CIVdata_filter %>%
  group_by(UAS.unit_id, cmsQuestions.question_number, UAS.lesson_id) %>%
  summarize(nQuestionsPerLesson = n_distinct(cmsQuestions.question_text))

questionsPerLesson_V02 = questionsPerLesson %>%
  group_by(UAS.unit_id, cmsQuestions.question_number) %>%
  summarize(nLessons = n_distinct(UAS.lesson_id),
            avgQuestionsPerLesson = round(mean(nQuestionsPerLesson),2),
            lessonsWithLessThan5Q = length(nQuestionsPerLesson[nQuestionsPerLesson<=4]),
            min = min(nQuestionsPerLesson),
            max = max(nQuestionsPerLesson))

datatable(questionsPerLesson_V02)  

```

####Unique Question Types and Performance
```{r VOS performance, echo = F}
questionPerformance = CIVdata_filter %>%
  group_by(UAS.unit_id,cmsQuestions.question_number) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            totalAttempts = sum(UAS.number_of_attempts),
          avgCorrectnessOfQuestionAttempts = round(mean(UAS.correct),2))

datatable(questionPerformance)
```

###Question List
####The full list of all unique combinations of question_type and token A/B/C combinations that students have attempted
####{.tabset}
#####All Questions
```{r question list, echo= F}
questionList = CIVdata_filter %>%
  group_by(UAS.unit_id, cmsQuestions.question_number,cmsQuestions.difficulty_level_trial,cmsQuestions.question_text) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            nAttempts = sum(inMichelsList),
            avgCorrectness = round(mean(UAS.correct),2))

datatable(questionList)
```

#####Questions Repeated Multiple Days
```{r}
questionList_Repeated = CIVdata_filter %>%
  group_by(UAS.unit_id, studentStudyId,cmsQuestions.question_number,cmsQuestions.difficulty_level_trial,cmsQuestions.question_text) %>%
  summarize(nDays = n_distinct(date),
            nAttempts = sum(inMichelsList),
            avgCorrectness = round(mean(UAS.correct),2)) %>%
  filter(nDays > 1)

datatable(questionList_Repeated)
```

###Summary of Question Distribution
```{r question summary, echo = F}
message(paste("Currently across all units:",n_distinct(questionList$cmsQuestions.question_text),"unique questions."))
message(paste("There are",nrow(questionList),"rows in the Question List above."))

```

<!-- ###Does a single question have multiple difficulty values? -->
<!-- ```{r} -->
<!-- #output the questions with multiple difficulty levels. should this be? -->


<!-- ``` -->

###Do any trials have chance accuracy even after 3 attempts?
####Two-option questions (cannot be re-attempted) show low accuracy rates on the first and only attempt
```{r, echo = F}
datatable(CIVdata_filter.trialid[CIVdata_filter.trialid$zLastAcc<1,c('trialID','students','presentations','options','LastAcc','zLastAcc')])
```

####Three-option questions improve considerably
```{r, echo = F}
datatable(CIVdata_filter.trialid)
```

###Comparing student performance across quartile splits on given unit/question types
####Ideally, there should be a discernible difference between Q1 and Q4 in each graph. If there is not, it may indicate question difficulty, technical difficulty, student unreadiness, etc.
```{r performance first lesson vs current lesson, echo = F}
performanceFirstLessonToCurrent = CIVdata_filter %>%
  group_by(studentStudyId, UAS.unit_id, usersToUnits.currentUnit, cmsQuestions.question_number) %>%
  mutate(questionAndUnit_concat = paste0(UAS.unit_id, "_",cmsQuestions.question_number),
         questionMax = max(questionNumberPerUnit),
         questionQuartile = questionNumberPerUnit / questionMax,
    #questionQuantile = rank(questionNumberPerUnit)/length(unique(questionNumberPerUnit)),
         questionQuartileGroup = ifelse(questionQuartile < .25, "Q1", 
                                        ifelse(questionQuartile >= .75, "Q2", 
                                               ifelse(questionQuartile >= .5, "Q3", "Q4")))) %>%
  group_by(studentStudyId, questionAndUnit_concat,usersToUnits.currentUnit,questionQuartileGroup) %>%
  summarize(avgCorrectPercent = round(mean(UAS.correct),2),
            sdCorrectPercent = round(sd(UAS.correct),2),
            nQuestions = n_distinct(questionNumberOverall))
  # group_by(questionAndUnit_concat, questionQuantileGroup) %>%
  # summarize(avgCorrectPercent = round(mean(avgCorrectPercent),2),
  #           sdCorrectPercent = round(sd(sdCorrectPercent),2),
  #           avgNQuestions = round(mean(nQuestions),2),
  #           sdNQuestions = round(sd(nQuestions),2),
  #           nStudents = n_distinct(studentStudyId))

datatable(performanceFirstLessonToCurrent)
```

####The plot shows the quartile split of all questions a student receives (x axis) by the average % correct on that quartile of questions (y axis). Each combination of a unit and question in its own plot (each plot's title corresponds to "Unit#_Question#"). From Quartile 1 to Quartile 4, we would hope to see the students performing better.

```{r, echo=F}
 performanceFirstLessonToCurrent %>%
 ggplot(aes(x = questionQuartileGroup, y = avgCorrectPercent)) +
   geom_jitter(alpha = .2, width = .2) +
   #stat_smooth(aes(group = usersToUnits.currentUnit)) +
   facet_wrap(~ questionAndUnit_concat, ncol = 5)
```



##2. Token Summary

###Token Distribution
####difficulty_level_token increases by 1 if certain phonemes don't exist in AttiÃ© and also if the token contains a certain syllable structure
####difficulty_level_trial increases by 1 for each shared phoneme (in the same position) between tokens
```{r token distribution, echo = F}
tokensInQuestions = CIVdata_filter %>%
  group_by(UAS.unit_id, cmsQuestions.question_number, cmsQuestions.difficulty_level_trial, cmsQuestions.difficulty_level_token) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            totalUniqueQuestions = n_distinct(cmsQuestions.id),
            totalAttempts = sum(inMichelsList),
            uniqueTokenA = n_distinct(cmsQuestions.token_a_id),
            uniqueTokenB = n_distinct(cmsQuestions.token_b_id),
            uniqueTokenC = n_distinct(cmsQuestions.token_c_id))

datatable(tokensInQuestions)
```


###Token Breakdown 
#####How to read this table: Starting with row 1, a row can be interpreted as 'token_a_id #20 was experienced by 5 students in 26 attempts of 3 unique questions, with an average correct respose rate of 0.69'
#####Sorting by avgAttemptCorrectness reveals a number of token_ids that have an average correctness below chance. This may indicate a number of different possibilities: the token is very difficult, the token is not being played so students are guessing because they hear silence, their environment was noisy and so they didn't hear the options, etc.

###{.tabset}

#### Token A List (correct answers)
```{r token list A, echo = F}
tokenDistribution_A = CIVdata_filter %>%
  group_by(cmsQuestions.token_a_id, phonetics_auditory_token_a, spelling_visual_token_a) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            uniqueQuestionTypesWithTokenA = n_distinct(cmsQuestions.id),
            countAttempts = sum(inMichelsList),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(tokenDistribution_A)
```

####Token B List (distractor)
```{r token list B, echo = F}
tokenDistribution_B = CIVdata_filter %>%
  group_by(cmsQuestions.token_b_id, phonetics_auditory_token_b, spelling_visual_token_b) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            uniqueQuestionsTypesWithTokenB = n_distinct(cmsQuestions.id),
            countAttempts = sum(inMichelsList),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(tokenDistribution_B)
  
```

####Token C List (distractor)
```{r token list C, echo = F}
tokenDistribution_C = CIVdata_filter %>%
  group_by(cmsQuestions.token_c_id, phonetics_auditory_token_c, spelling_visual_token_c) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            uniqueQuestionTypesWithTokenC = n_distinct(cmsQuestions.id),
            countAttempts = sum(inMichelsList),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(tokenDistribution_C)
```

###Distractor Token Co-Occurrence?
####distractor_token value of "null" occurs on true/false questions. I left that in for comparison to the non-true/false questions.
```{r distractor token co-occurrence, echo = F}

tokenDistribution_distractorBC = CIVdata_filter %>%
  ungroup() %>%
  group_by(cmsQuestions.distractor_tokens_V02, cmsQuestions.distractor_tokens_IPA, cmsQuestions.distractor_tokens_spelling) %>%
  summarize(nStudents = n_distinct(studentStudyId),
            uniqueQuestionTypesWithTokenPair = n_distinct(cmsQuestions.id),
            countAttempts = sum(inMichelsList),
            avgAttemptCorrectness = round(mean(UAS.correct),2))

datatable(tokenDistribution_distractorBC)
```

###Summary of Token Distribution
```{r token summary, echo = F}
message(paste("Currently across all tokens:",nrow(tokenDistribution_A),"unique token As,",nrow(tokenDistribution_B), "unique token Bs, and",nrow(tokenDistribution_C),"unique token Cs have been used in at least one question. There are",nrow(tokenDistribution_distractorBC),"unique combinations of Tokens B and C."))
```

### Which tokens are most frequently presented?
####The histogram indicates the number of times tokens were presented, e.g. the first bar indicates that ~17 unique tokens were produced a total of 1 time to students.
```{r, echo = F}

CIVdata_filter.tokenid %>%
  ggplot(aes(x = presentations)) +
  geom_histogram(binwidth = 1)

#original hist code from Ben
#hist(CIVdata_filter.tokenid$presentations)
tweight.mean <- round(mean(CIVdata_filter.tokenid$presentations),2)
tweight.sd <- round(sd(CIVdata_filter.tokenid$presentations),2)

# Low frequency tokens (code included for completeness, but commented out for now)
# Spoiler, there aren't any (since the zero-frequency tokens don't get included)
#CIVdata_filter.tokenid[CIVdata_filter.tokenid$presentations < tweight.mean-2*tweight.sd,]
```

####High Frequency tokens displayed (based on standard deviation of selection rates). Low frequency tokens don't appear in the data since zero-freuqncy tokens are by default excluded.
```{r, echo = F}
# High frequency tokens
datatable(CIVdata_filter.tokenid[CIVdata_filter.tokenid$presentations > tweight.mean+2*tweight.sd,])

```

###Which tokens have low accuracy in first and last attempts?
####Low accuracy on first attempts
```{r, echo = F}
CIVdata_filter.tokenid %>%
  ggplot(aes(x = FirstAcc)) +
  geom_histogram(binwidth = .1 )

#hist(CIVdata_filter.tokenid$FirstAcc)
# Low accuracy first-attempts: 
# When there are at least 5 presentations to average across, and accuracy is equal to or below chance
datatable(CIVdata_filter.tokenid[CIVdata_filter.tokenid$zFirstAcc<=0 & CIVdata_filter.tokenid$presentations>=5,])
```

####Low accuracy on last attempts
```{r, echo = F}

CIVdata_filter.tokenid %>%
  ggplot(aes(x = LastAcc)) +
  geom_histogram(binwidth = .1 )

#hist(CIVdata_filter.tokenid$LastAcc)
# Low accuracy last-attempts tokens:
# When there are at least 5 presentations to average across, and accuracy is near or below chance
# Even some greater-than-chance results included, because they should be learnable by 3rd attempt
datatable(CIVdata_filter.tokenid[CIVdata_filter.tokenid$zLastAcc<=1 & CIVdata_filter.tokenid$presentations>=5,])

```

###Does token difficulty rating accurately predict first- or last-attempt performance? 
###{.tabset}

####Difficulty (first attempt)

```{r, echo = F}
token_diff <- cor.test(CIVdata_filter.tokenid$tokenDifficulty, CIVdata_filter.tokenid$zFirstAcc,weights=CIVdata_filter.tokenid$presentations)
token_diff
```   
 
####Learnability (last attempt)
```{r, echo = F}
token_lern <- cor.test(CIVdata_filter.tokenid$tokenDifficulty, CIVdata_filter.tokenid$zLastAcc,weights=CIVdata_filter.tokenid$presentations)
token_lern
```




##3. Syllable analysis
###What syllable structures have been used and what have been excluded so far?
####Blank FirstAcc or LastAcc means that the token has not been presented to any students yet
```{r, echo = F}
# Count the number of total presentations for each syllable structure
# Check the difficulty and learnability of each of the presented syllable structures
#CIVdata_filter.syllable <- CIVdata_filter.tokenid.ALLtokens %>%
CIVdata_filter.syllable <- CIVdata_filter.tokenid %>%
  ungroup() %>%
  group_by(token_a_syllable_structure) %>%
  summarise(
    presentations = sum(presentations,na.rm=TRUE),
    FirstAcc = round(mean(FirstAcc,na.rm=TRUE),2),
    LastAcc = round(mean(LastAcc,na.rm=TRUE),2)
  )
datatable(CIVdata_filter.syllable)
```

###Does syllable structure significantly affect the token difficulty?
####List the current syllables
```{r, echo = F}
CIVdata_filter.tokenid$token_a_syllable_structure = as.factor(CIVdata_filter.tokenid$token_a_syllable_structure)
CIVdata_filter.tokenid$token_a_syllable_structure <- relevel(CIVdata_filter.tokenid$token_a_syllable_structure,'CVC')
unique(CIVdata_filter.tokenid$token_a_syllable_structure)
```


####There is no significant difference in syllable_structure and first attempt accuracy
```{r, echo = F}
# Perform ANOVA to determine whether syllable structures significantly differ from each other in first-attempt accuracy
syllable_effect_zF <- lm(zFirstAcc~token_a_syllable_structure,CIVdata_filter.tokenid,weight=CIVdata_filter.tokenid$presentations)
#summary(syllable_effect_zF)
anova(syllable_effect_zF)
```

####There is a significant difference in syllable_structure and last attempt accuracy
```{r, echo = F}
# Perform ANOVA to determine whether syllable structures significantly differ from each other in last-attempt accuracy
syllable_effect_zL <- lm(zLastAcc~token_a_syllable_structure,CIVdata_filter.tokenid,weight=CIVdata_filter.tokenid$presentations)
#summary(syllable_effect_zL)
anova(syllable_effect_zL)
```

<!-- ```{r} -->
<!-- summary(lmer(UAS.correct ~ UAS.unit_id + cmsQuestions.difficulty_level_token + cmsQuestions.difficulty_level_trial + (1|studentStudyId), data = CIVdata_filter)) -->

<!-- ``` -->

<!-- ##4. Token Type Analysis -->

<!-- ###Does token type significantly affect the token difficulty? -->
<!-- ####List the current token types -->
<!-- ```{r, echo = F} -->
<!-- CIVdata_filter.tokenid$token_a_type = as.factor(CIVdata_filter.tokenid$token_a_type) -->
<!-- unique(CIVdata_filter.tokenid$token_a_type) -->
<!-- #note: 1 = word; 2 = syllable; 3 = phoneme -->
<!-- ``` -->

<!-- ```{r} -->
<!-- type_effect_zF <- lm(zFirstAcc~token_a_type,CIVdata_filter.tokenid,weight=CIVdata_filter.tokenid$presentations) -->
<!-- #summary(syllable_effect_zF) -->
<!-- anova(type_effect_zF) -->

<!-- summary(LSD.test(type_effect_zF, CIVdata_filter.tokenid$token_a_type)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- type_effect_zL <- lm(zLastAcc~token_a_type,CIVdata_filter.tokenid,weight=CIVdata_filter.tokenid$presentations) -->
<!-- #summary(syllable_effect_zF) -->
<!-- anova(type_effect_zL) -->

<!-- x = HSD.test(type_effect_zL, "token_a_type", group = TRUE) -->
<!-- summary(x) -->

<!-- ``` -->

<!-- ##5. Promotion Analysis -->

<!-- ###thresholds -->
<!-- ```{r} -->

<!-- studentThreshold = CIVdata_filter %>% -->
<!--   group_by(UAS.unit_id) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId)) %>% -->
<!--   mutate( -->
<!--          thresh85 = round(nStudents * .85), -->
<!--          thresh75 = round(nStudents * .75), -->
<!--          thresh50 = round(nStudents * .50), -->
<!--          thresh25 = round(nStudents * .25) -->
<!--          ) -->

<!-- datatable(studentThreshold) -->

<!-- ``` -->

<!-- ###Questions prior to promotion -->

<!-- ```{r} -->

<!-- #questionsForPromotion =  -->

<!-- ``` -->

<!-- ```{r} -->
<!-- #questions per unit -->
<!-- qPerUnit = CIVdata_filter %>% -->
<!--   #filter(questionNumberPerUnit <= 100) %>% -->
<!--   group_by(UAS.unit_id, questionNumberPerUnit) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId), -->
<!--             percentCorrectAttempts = round(mean(UAS.correct))) %>% -->
<!--   filter(UAS.unit_id == 1) %>% -->
<!--   ggplot(aes(x = questionNumberPerUnit, y = percentCorrectAttempts, color = UAS.unit_id)) + -->
<!--   scale_y_continuous(limits = c(0, 1)) + -->
<!--   #geom_jitter(alpha = .2, width = .2) +  -->
<!--   stat_smooth(aes(group = UAS.unit_id))   -->

<!-- qPerUnit -->
<!-- ``` -->


<!-- ```{r} -->
<!-- #questions per lesson -->
<!-- qPerLesson = CIVdata_filter %>% -->
<!--   filter(lessonNumberPerUnit <= 200) %>% -->
<!--   group_by(UAS.unit_id, lessonNumberPerUnit, questionNumberPerLesson) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId), -->
<!--             percentCorrectAttempts = round(mean(UAS.correct),2)) %>% -->
<!--   filter(nStudents > 25) %>% -->
<!--   ggplot(aes(x = questionNumberPerLesson, y = percentCorrectAttempts)) + -->
<!--   #geom_jitter(alpha = .2, width = .2) + -->
<!--   scale_y_continuous(limits = c(0, 1)) + -->
<!--   stat_smooth()   -->

<!-- qPerLesson -->
<!-- ``` -->


<!-- ```{r} -->
<!-- qOverall = CIVdata_filter %>% -->
<!--   filter(questionNumberOverall <= 25) %>% -->
<!--   group_by(questionNumberOverall) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId), -->
<!--             percentCorrectAttempts = round(mean(UAS.correct),2)) %>% -->
<!--   #filter(nStudents > 30) %>% -->
<!--   ggplot(aes(x = questionNumberOverall, y = percentCorrectAttempts)) + -->
<!--   #geom_jitter(alpha = .2, width = .2) + -->
<!--   scale_y_continuous(limits = c(0, 1)) + -->
<!--   stat_smooth()   -->

<!-- qOverall -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # #attempt overall -->
<!-- # aOverall = CIVdata_filter %>% -->
<!-- #   filter(options == 3 & attemptNumber <= 3 & questionNumberPerUnit < 150) %>% -->
<!-- #   group_by(options, attemptNumber) %>% -->
<!-- #   summarize(nStudents = n_distinct(studentStudyId), -->
<!-- #             percentCorrectAttempts = round(mean(UAS.correct),2)) %>% -->
<!-- #   #filter(nStudents > 30) %>% -->
<!-- #   ggplot(aes(x = attemptNumber, y = percentCorrectAttempts)) + -->
<!-- #   #geom_jitter(alpha = .2, width = .2) + -->
<!-- #   scale_y_continuous(limits = c(0, 1)) + -->
<!-- #   stat_smooth()   -->
<!-- #  -->
<!-- # aOverall -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #attempt per question -->
<!-- aPerQuestion = CIVdata_filter %>% -->
<!--   #filter(lessonNumberPerUnit <= 200) %>% -->
<!--   group_by(UAS.unit_id, lessonNumberPerUnit, questionNumberPerLesson, attemptNumber) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId), -->
<!--             percentCorrectAttempts = round(mean(UAS.correct),2)) %>% -->
<!--   filter(nStudents > 25) %>% -->
<!--   ggplot(aes(x = questionNumberPerLesson, y = percentCorrectAttempts)) + -->
<!--   #geom_jitter(alpha = .2, width = .2) + -->
<!--   scale_y_continuous(limits = c(0, 1)) + -->
<!--   stat_smooth()   -->

<!-- qPerLesson -->

<!-- ``` -->

<!-- ```{r} -->
<!-- #attempt per lesson -->
<!-- aPerLesson = CIVdata_filter %>% -->
<!--   filter(attemptNumber <= 3 & lessonNumberPerUnit <= 200) %>% -->
<!--   group_by(studentStudyId, UAS.unit_id, lessonNumberPerUnit, questionNumberPerLesson, attemptNumber) %>% -->
<!--   summarize(percentCorrect = round(mean(UAS.correct),2)) %>% -->
<!--   ungroup() %>% -->
<!--   group_by(UAS.unit_id, lessonNumberPerUnit, attemptNumber) %>% -->
<!--   summarize(nStudents = n_distinct(studentStudyId), -->
<!--             percentCorrectAttempts = round(mean(percentCorrect),2)) %>% -->
<!--   filter(nStudents > 10) %>% -->
<!--   ggplot(aes(x = attemptNumber, y = percentCorrectAttempts)) + -->
<!--   #geom_jitter(alpha = .2, width = .2) + -->
<!--   scale_y_continuous(limits = c(0, 1)) + -->
<!--   stat_smooth()   -->

<!-- aPerLesson -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #attempt per unit -->


<!-- ``` -->

<!-- ```{r} -->
<!-- #lesson overall -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #lesson per unit -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #unit overall -->
<!-- ``` -->

